// Copyright Â© 2017 NAME HERE <EMAIL ADDRESS>
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package server

import (
	"fmt"
	"html/template"
	goio "io"
	"io/ioutil"
	"log"
	"mime/multipart"
	"net/http"
	"os"
	"os/signal"
	"path/filepath"
	"runtime"
	"sync"
	"syscall"
	"time"

	"github.com/fredericlemoine/booster-web/config"
	"github.com/fredericlemoine/booster-web/database"
	"github.com/fredericlemoine/booster-web/io"
	"github.com/fredericlemoine/booster-web/model"
	"github.com/fredericlemoine/booster-web/static"
	"github.com/fredericlemoine/booster-web/templates"
	"github.com/fredericlemoine/gotree/support"
	"github.com/nu7hatch/gouuid"
	"github.com/russross/blackfriday"
)

const (
	DATABASE_TYPE_DEFAULT      = "memory"
	RUNNERS_QUEUESIZE_DEFAULT  = 10
	RUNNERS_NBRUNNERS_DEFAULT  = 1
	RUNNERS_TIMEOUT_DEFAULT    = 0 // unlimited
	RUNNERS_JOBTHREADS_DEFAULT = 1
	HTTP_PORT_DEFAULT          = 8080 // Port 8080
)

var templatePath string

var templatesMap map[string]*template.Template

var db database.BoosterwebDB

var queue chan *model.Analysis // queue of analyses
var uuids chan string          // channel of uuids generated by a go routine

var logfile *os.File = nil
var lock sync.RWMutex

var runningJobs map[string]*model.Analysis

// The config should contain following keys:
// runners.queuesize: Max number of jobs in the queue (default 10)
// runners.nbrunners: Max number of parallel running jobs (default 1)
// runners.timeout for each running job in Seconds (default 0=unlimited)
// runners.jobthreads : Number of cpus per bootstrap runner
// database.type: mysql or memory (default memory)
// database.user: user to connect to mysql if type is mysql
// database.host: host to connect to mysql if type is mysql
// database.port: port to connect to mysql if type is mysql
// database.pass: pass to connect to mysql if type is mysql
// database.dbname: name of db to connect to mysql if type is mysql
// logging.logfile : path to log file: stdout, stderr or any file name (default stderr)
func InitServer(cfg config.Provider) {
	initLog(cfg)
	log.Print("Starting booster-web")
	initUUIDGenerator()
	initRunners(cfg)
	initCleanKill()
	initDB(cfg)

	templatePath = "webapp" + string(os.PathSeparator) + "templates" + string(os.PathSeparator)

	formtpl, err1 := templates.Asset(templatePath + "inputform.html")
	if err1 != nil {
		log.Fatal(err1)
	}
	errtpl, err2 := templates.Asset(templatePath + "error.html")
	if err2 != nil {
		log.Fatal(err2)
	}
	viewtpl, err3 := templates.Asset(templatePath + "view.html")
	if err3 != nil {
		log.Fatal(err3)
	}
	indextpl, err4 := templates.Asset(templatePath + "index.html")
	if err4 != nil {
		log.Fatal(err4)
	}
	layouttpl, err5 := templates.Asset(templatePath + "layout.html")
	if err5 != nil {
		log.Fatal(err5)
	}
	helptpl, err6 := templates.Asset(templatePath + "help.html")
	if err6 != nil {
		log.Fatal(err6)
	}

	templatesMap = make(map[string]*template.Template)

	if t, err := template.New("inputform").Parse(string(layouttpl) + string(formtpl)); err != nil {
		log.Fatal(err)
	} else {
		templatesMap["inputform"] = t
	}

	if t, err := template.New("error").Parse(string(layouttpl) + string(errtpl)); err != nil {
		log.Fatal(err)
	} else {
		templatesMap["error"] = t
	}

	if t, err := template.New("view").Parse(string(layouttpl) + string(viewtpl)); err != nil {
		log.Fatal(err)
	} else {
		templatesMap["view"] = t
	}

	if t, err := template.New("index").Parse(string(layouttpl) + string(indextpl)); err != nil {
		log.Fatal(err)
	} else {
		templatesMap["index"] = t
	}

	if t, err := template.New("help").Funcs(template.FuncMap{"markDown": markDowner}).Parse(string(layouttpl) + string(helptpl)); err != nil {
		log.Fatal(err)
	} else {
		templatesMap["help"] = t
	}

	/* HTML handlers */
	http.HandleFunc("/new/", newHandler)                /* Handler for input form */
	http.HandleFunc("/run", runHandler)                 /* Handler for running a new analysis */
	http.HandleFunc("/help", helpHandler)               /* Handler for the help page */
	http.HandleFunc("/view/", makeHandler(viewHandler)) /* Handler for viewing analysis results */
	http.HandleFunc("/itol/", makeHandler(itolHandler)) /* Handler for uploading tree to itol */
	http.HandleFunc("/", indexHandler)                  /* Home Page*/

	/* Api handlers */
	http.HandleFunc("/api/analysis/", makeApiHandler(apiAnalysisHandler)) /* Handler for returning an analysis */

	/* Static files handlers : js, css, etc. */
	http.Handle("/static/", http.FileServer(static.AssetFS()))
	//http.Handle("/", http.RedirectHandler("/new/", http.StatusFound))

	port := cfg.GetInt("http.port")
	if port == 0 {
		port = HTTP_PORT_DEFAULT
	}
	log.Print(fmt.Sprintf("HTTP port: %d", port))
	log.Fatal(http.ListenAndServe(fmt.Sprintf(":%d", port), nil))
}

func initRunners(cfg config.Provider) {
	var maxcpus int = runtime.NumCPU() // max number of cpus

	runningJobs = make(map[string]*model.Analysis)
	nbrunners := cfg.GetInt("runners.nbrunners")
	queuesize := cfg.GetInt("runners.queuesize")
	timeout := cfg.GetInt("runners.timeout")
	jobthreads := cfg.GetInt("runners.jobthreads")

	if jobthreads == 0 {
		jobthreads = RUNNERS_JOBTHREADS_DEFAULT
	}

	if nbrunners == 0 {
		nbrunners = RUNNERS_NBRUNNERS_DEFAULT
	}
	if (nbrunners*jobthreads + 1) > maxcpus {
		log.Fatal(fmt.Sprintf("Your system does not have enough cpus to run the http server + %d bootstrap runners with each %d threads", nbrunners, jobthreads))
	}

	if queuesize == 0 {
		queuesize = RUNNERS_QUEUESIZE_DEFAULT
	}
	if queuesize <= 0 {
		log.Fatal("The queue size must be set to a value >0")
	}
	if queuesize < 100 {
		log.Print("The queue size is <100, it may be a problem for users")
	}

	log.Print(fmt.Sprintf("Nb runners: %d", nbrunners))
	log.Print(fmt.Sprintf("Queue size: %d", queuesize))
	log.Print(fmt.Sprintf("Job timeout: %ds", timeout))
	log.Print(fmt.Sprintf("Job threads: %d", jobthreads))

	queue = make(chan *model.Analysis, queuesize)

	// We initialize computing routines
	for cpu := 0; cpu < nbrunners; cpu++ {
		go func(cpu int) {
			for a := range queue {
				log.Print(fmt.Sprintf("CPU=%d | New analysis, id=%s", cpu, a.Id))

				a.Status = model.STATUS_RUNNING
				a.StartRunning = time.Now().Format(time.RFC1123)
				a.StatusStr = model.StatusStr(a.Status)
				supporter := &support.BoosterSupporter{}
				finished := false
				db.UpdateAnalysis(a)
				newRunningJob(a)
				var wg sync.WaitGroup // For waiting end of step computation
				wg.Add(1)
				go func() {
					t, err := support.ComputeSupport(a.Reffile, a.Bootfile, os.Stderr, false, jobthreads, supporter)
					a.End = time.Now().Format(time.RFC1123)

					if err != nil {
						io.LogError(err)
						a.Message = err.Error()
						a.Status = model.STATUS_ERROR
						a.StatusStr = model.StatusStr(a.Status)
					} else {
						if supporter.Canceled() {
							a.Status = model.STATUS_TIMEOUT
							a.StatusStr = model.StatusStr(a.Status)
						} else {
							a.Status = model.STATUS_FINISHED
							a.StatusStr = model.StatusStr(a.Status)
						}
						t.ClearPvalues()
						a.Result = t.Newick()
						a.Collapsed = a.Result
						a.Message = "Finished"
					}
					db.UpdateAnalysis(a)
					rmRunningJob(a)
					delTemp(a)
					wg.Done()
				}()

				go func() {
					for {
						a.Nboot = supporter.Progress()
						db.UpdateAnalysis(a)
						if finished {
							break
						}
						time.Sleep(4 * time.Second)
					}
				}()

				if timeout > 0 {
					go func() {
						time.Sleep(time.Duration(timeout) * time.Second)
						if !finished {
							supporter.Cancel()
						}
					}()
				}
				wg.Wait()
				a.Nboot = supporter.Progress()
				db.UpdateAnalysis(a)
				finished = true
			}
			log.Print(fmt.Sprintf("CPU %d : End", cpu))
		}(cpu)
	}
}

func initUUIDGenerator() {
	uuids = make(chan string, 100)
	// The uuid generator will put uuids in the channel
	// When a new analysis is launched, one uuid will be taken
	// from the channel
	go func() {
		for {
			u, err := uuid.NewV4()
			if err != nil {
				log.Print(err)
			} else {
				uuids <- u.String()
			}
		}
	}()
}

func initCleanKill() {

	c := make(chan os.Signal, 1)
	signal.Notify(c, os.Interrupt,
		syscall.SIGHUP,
		syscall.SIGINT,
		syscall.SIGTERM,
		syscall.SIGQUIT)

	go func() {
		for sig := range c {
			log.Print(sig)
			for _, a := range allRunningJobs() {
				log.Print("Cancelling job : " + a.Id)
				a.Status = model.STATUS_CANCELED
				a.End = time.Now().Format(time.RFC1123)
				a.Message = "Canceled after a server restart"
				if err := db.UpdateAnalysis(a); err != nil {
					log.Print(err)
				}
			}
			if err := db.Disconnect(); err != nil {
				log.Print(err)
			}
			os.Exit(1)
		}
	}()
}

func initDB(cfg config.Provider) {
	dbtype := cfg.GetString("database.type")
	switch dbtype {
	case "memory":
		db = database.NewMemoryBoosterWebDB()
	case "mysql":
		user := cfg.GetString("database.user")
		host := cfg.GetString("database.host")
		pass := cfg.GetString("database.pass")
		dbname := cfg.GetString("database.dbname")
		port := cfg.GetInt("database.port")
		db = database.NewMySQLBoosterwebDB(user, pass, host, dbname, port)
		if err := db.Connect(); err != nil {
			log.Fatal(err)
		}
	default:
		db = database.NewMemoryBoosterWebDB()
		log.Print("Database type not valid, using default: " + DATABASE_TYPE_DEFAULT)
	}

	if err := db.InitDatabase(); err != nil {
		log.Fatal(err)
	}
}

func initLog(cfg config.Provider) {
	logf := cfg.GetString("logging.logfile")
	switch logf {
	case "stderr":
		log.Print("Log file: stderr")
		logfile = os.Stderr
	case "stdout":
		log.Print("Log file: stdout")
		logfile = os.Stdout
	case "":
		log.Print("Log file: stderr")
		logfile = os.Stderr
	default:
		log.Print("Log file: " + logf)
		var err error
		logfile, err = os.OpenFile(logf, os.O_RDWR|os.O_CREATE|os.O_APPEND, 0666)
		if err != nil {
			log.Fatal(err)
		}
	}
	log.SetOutput(logfile)
}

func newAnalysis(reffile multipart.File, refheader *multipart.FileHeader, bootfile multipart.File, bootheader *multipart.FileHeader) (a *model.Analysis) {

	/* TODO: Read all from ref reader and bootreader and save them in temp files (gz) */
	uuid := <-uuids

	a = &model.Analysis{
		uuid,
		"",
		"",
		"",
		model.STATUS_PENDING,
		model.StatusStr(model.STATUS_PENDING),
		"",
		0,
		"",
		time.Now().Format(time.RFC1123),
		"",
		"",
	}

	log.Print(fmt.Sprintf("New analysis submited | id=%s | Queue length is %d: ", a.Id, len(queue)))

	/* tmp analysis folder */
	dir, err := ioutil.TempDir("", uuid)
	if err != nil {
		log.Print(err)
		a.Status = model.STATUS_CANCELED
		a.StatusStr = model.StatusStr(a.Status)
		a.Message = err.Error()
		err = db.UpdateAnalysis(a)
		return
	}
	reftree := filepath.Join(dir, refheader.Filename)
	boottrees := filepath.Join(dir, bootheader.Filename)
	ref, err1 := os.OpenFile(reftree, os.O_WRONLY|os.O_CREATE, 0666)
	if err1 != nil {
		log.Print(err)
		a.Status = model.STATUS_CANCELED
		a.StatusStr = model.StatusStr(a.Status)
		a.Message = err1.Error()
		err = db.UpdateAnalysis(a)
		delTemp(a)
		return
	}

	boot, err2 := os.OpenFile(boottrees, os.O_WRONLY|os.O_CREATE, 0666)
	if err2 != nil {
		log.Print(err)
		a.Status = model.STATUS_CANCELED
		a.StatusStr = model.StatusStr(a.Status)
		a.Message = err2.Error()
		err = db.UpdateAnalysis(a)
		delTemp(a)
		return
	}
	goio.Copy(ref, reffile)
	goio.Copy(boot, bootfile)
	ref.Close()
	boot.Close()

	a.Reffile = reftree
	a.Bootfile = boottrees

	if err != nil {
		log.Print(err)
		a.Status = model.STATUS_CANCELED
		a.StatusStr = model.StatusStr(a.Status)
		a.Message = err.Error()
		delTemp(a)
		db.UpdateAnalysis(a)
		return
	}

	/* Insert analysis */
	err = db.UpdateAnalysis(a)

	select {
	case queue <- a: // Put a in the channel unless it is full
	default:
		//Channel full. Discarding value
		a.Status = model.STATUS_CANCELED
		a.StatusStr = model.StatusStr(a.Status)
		a.End = time.Now().Format(time.RFC1123)
		a.Message = "Computing queue is full, please try again in a few minutes"
		/* Insert analysis */
		err = db.UpdateAnalysis(a)
		delTemp(a)
	}
	return
}

func getAnalysis(id string) (a *model.Analysis, err error) {
	a, err = db.GetAnalysis(id)
	return
}

func markDowner(args ...interface{}) template.HTML {
	s := blackfriday.MarkdownCommon([]byte(fmt.Sprintf("%s", args...)))
	return template.HTML(s)
}

func delTemp(a *model.Analysis) {
	if err := os.Remove(a.Reffile); err != nil {
		log.Print(err)
	}
	if err := os.Remove(a.Bootfile); err != nil {
		log.Print(err)
	}
	if err := os.Remove(filepath.Dir(a.Bootfile)); err != nil {
		log.Print(err)
	}
}

/**
Keep a trace of currently running jobs
In order to cancel them when the server stops
*/
func newRunningJob(a *model.Analysis) {
	lock.Lock()
	defer lock.Unlock()

	runningJobs[a.Id] = a
}

func rmRunningJob(a *model.Analysis) {
	lock.Lock()
	defer lock.Unlock()

	delete(runningJobs, a.Id)
}

func allRunningJobs() []*model.Analysis {
	lock.RLock()
	defer lock.RUnlock()
	v := make([]*model.Analysis, 0)
	for _, value := range runningJobs {
		v = append(v, value)
	}
	return v
}
